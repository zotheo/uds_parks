{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc95c411-7b89-4a04-b2cf-3caa214405cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1152895909.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda install webdriver-manager selenium pandas\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##run this first to install package, then delete\n",
    "conda install webdriver-manager selenium pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9796949-49e1-47a6-8803-b271ee4efc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import time \n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "from selenium.webdriver import Chrome \n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.common.by import By \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a817af-dc9d-428f-91a4-5daf971c6928",
   "metadata": {},
   "source": [
    "Run this block below as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c58244-796c-4663-b692-e17515692114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/c90tdsjn63g4803dfq4s7w4m0000gn/T/ipykernel_68579/210964506.py:3: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True # it's more scalable to work in headless mode\n"
     ]
    }
   ],
   "source": [
    "# start by defining the options \n",
    "options = webdriver.ChromeOptions() \n",
    "options.headless = True # it's more scalable to work in headless mode \n",
    "# normally, selenium waits for all resources to download \n",
    "# we don't need it as the page also populated with the running javascript code. \n",
    "options.page_load_strategy = 'none' \n",
    "# this returns the path web driver downloaded \n",
    "chrome_path = ChromeDriverManager().install() \n",
    "chrome_service = Service(chrome_path) \n",
    "# pass the defined options and service objects to initialize the web driver \n",
    "driver = Chrome(options=options, service=chrome_service) \n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0be8e-b24d-4b77-81fc-8c2e3912ae0b",
   "metadata": {},
   "source": [
    "This stores a list of listing urls based on a desired quantity (each listing page contains 120 listings). I'm keeping the number low for now, just for efficiency but we'll have to discuss how many individual listings we want to try and scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9f1ff4-3044-4aba-897a-0fb746f2f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "page = 0\n",
    "num_pages = 77\n",
    "\n",
    "# get urls\n",
    "for x in range(num_pages):\n",
    "    page += 1 \n",
    "    url_list.append(\"https://losangeles.craigslist.org/search/apa?query=los%20angeles#search=1~list~{}~0\".format(page))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc275619-c081-4895-900e-0011d25c41ab",
   "metadata": {},
   "source": [
    "For each page of listings, we need to grab the urls for each of the 120 individual listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6947e64a-8455-4c27-a670-afa4a8232c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://losangeles.craigslist.org/wst/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://losangeles.craigslist.org/wst/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://losangeles.craigslist.org/wst/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://losangeles.craigslist.org/lac/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://losangeles.craigslist.org/lac/apa/d/lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                urls\n",
       "0  https://losangeles.craigslist.org/wst/apa/d/lo...\n",
       "1  https://losangeles.craigslist.org/wst/apa/d/lo...\n",
       "2  https://losangeles.craigslist.org/wst/apa/d/lo...\n",
       "3  https://losangeles.craigslist.org/lac/apa/d/lo...\n",
       "4  https://losangeles.craigslist.org/lac/apa/d/lo..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings = []\n",
    "\n",
    "for url in url_list:\n",
    "    # create WebElement of Listings Page\n",
    "    driver.get(url)\n",
    "    \n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    # find the section the listings are located in\n",
    "    content = driver.find_element(By.CSS_SELECTOR, \"div[class*='cl-results-page'\")\n",
    "    \n",
    "    # find the section where the link to the property page is located for each 120 listings\n",
    "    for element in content.find_elements(By.TAG_NAME, \"li\")[1:]:\n",
    "        try:\n",
    "            listings.append(element.find_elements(By.CSS_SELECTOR, \"div[class*='result-node-wide']>a\")[0].get_attribute(\"href\"))\n",
    "            \n",
    "        except (StaleElementReferenceException, NoSuchElementException) as e:\n",
    "            listings.append('NA')\n",
    "    \n",
    "            \n",
    "    # add delay (not sure about actually length of time delays necessary)\n",
    "    time.sleep(random.randint(1, 3))\n",
    "    \n",
    "listingsDf = pd.DataFrame(listings)\n",
    "listingsDf.rename(columns = {0:\"urls\"}, inplace = True)\n",
    "# limiting size for testing\n",
    "listingsDf = listingsDf\n",
    "# check DF\n",
    "listingsDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f36bb-26c9-4930-988e-95251310fdc1",
   "metadata": {},
   "source": [
    "Now we will scrape each webpage from the list of urls. This is where most of our development and discussion needs to occur. I've placed a temporary simple test in there for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d155141-5b57-4007-b93f-ad0be7e1b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf[listingsDf.urls == 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a5257-de32-4113-9b26-06d0737eb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim = listingsDf[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971acbc8-2446-4769-aba4-484e2684151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)\n",
    "\n",
    "\n",
    "for url in listingsDf_trim['urls']:\n",
    "    # create WebElement of listing URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    driver.maximize_window() # For maximizing window\n",
    "    driver.implicitly_wait(5) # gives an implicit wait for 20 seconds\n",
    "   \n",
    "    # grab description of listing and add to list\n",
    "    try:\n",
    "        #description\n",
    "        description.append(WebDriverWait(driver, 5,ignored_exceptions=ignored_exceptions)\\\n",
    "                        .until(expected_conditions.presence_of_element_located((By.ID, \"postingbody\"))).text)\n",
    "        \n",
    "        #lat\n",
    "        latitude_element = WebDriverWait(driver, 5, ignored_exceptions=ignored_exceptions).until(\n",
    "                        expected_conditions.presence_of_element_located((By.ID, \"map\"))\n",
    "                        )\n",
    "        latitude_value = latitude_element.get_attribute(\"data-latitude\")\n",
    "        latitude.append(latitude_value)\n",
    "                \n",
    "        #long\n",
    "        longitude_element = WebDriverWait(driver, 5, ignored_exceptions=ignored_exceptions).until(\n",
    "                        expected_conditions.presence_of_element_located((By.ID, \"map\"))\n",
    "                        )\n",
    "        longitude_value = longitude_element.get_attribute(\"data-longitude\")\n",
    "        longitude.append(longitude_value)\n",
    "        \n",
    "    except (StaleElementReferenceException, NoSuchElementException, TimeoutException) as e:\n",
    "        description.append('NA')\n",
    "        latitude.append('NA')\n",
    "        longitude.append('NA')\n",
    "    \n",
    "    time.sleep(random.randint(1, 3))\n",
    "    \n",
    "listingsDf_trim['description'] = description\n",
    "listingsDf_trim['lat'] = latitude\n",
    "listingsDf_trim['long'] = longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d1438-b946-4db2-b400-4011bee36727",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb61af3-d749-455a-920a-7b52fda3ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42066e0-b8f6-47f2-aa99-02e57fa47cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f606d-0155-4d6d-a823-3f1a1c5254bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_and_clean(text):\n",
    "    text = re.sub((\"\\n\"), \" \", text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "listingsDf_trim['description'] = listingsDf_trim['description'].apply(remove_and_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34a96c-acbe-43c6-95fd-632ada5c8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "parks = gpd.read_file('county_parks.geojson')\n",
    "parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ba100-2ec0-46d2-9fe8-db7636d24739",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim['park_TF'] = listingsDf_trim['description'].apply(lambda x: any(substring in x for substring in parks['PARK_NAME'].str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25253e4-e491-4f2f-bcbb-49e69371f41f",
   "metadata": {},
   "source": [
    "<div id=\"map\" class=\"viewposting leaflet-container leaflet-retina leaflet-fade-anim leaflet-grab leaflet-touch-drag\" data-latitude=\"33.959712\" data-longitude=\"-118.419410\" data-accuracy=\"10\" tabindex=\"0\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c28310-0e1d-4b0e-9406-bce1bfd8dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim.park_TF.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc45885a-e66c-443b-8f85-2bd8972d44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim[listingsDf_trim['park_TF'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8a138-b919-40a5-92de-6e070ca3629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsDf_trim = listingsDf_trim[listingsDf_trim['lat'] != 'NA']\n",
    "test = gpd.GeoDataFrame(listingsDf_trim, geometry=gpd.points_from_xy(listingsDf_trim.long, listingsDf_trim.lat), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb14a8-0b79-44aa-8402-e763b252c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# create scatter map\n",
    "fig = px.scatter_mapbox(test, lat=test.geometry.y, lon=test.geometry.x, color=\"park_TF\",\n",
    "                               mapbox_style=\"carto-positron\",\n",
    "                               #range_color=range_color,\n",
    "                               zoom=9,\n",
    "                               center = {\"lat\": 34, \"lon\": -118.4},\n",
    "                               opacity=.8,\n",
    "\n",
    "                               )\n",
    "\n",
    "# options on the layout\n",
    "fig.update_layout(\n",
    "        width = 900,\n",
    "        height = 700,\n",
    "        title = \"Listings\",\n",
    "        title_x = .5\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c37955-8de2-4b15-bcac-de6ecf2c91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.to_pickle(\"./dummy.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
