{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95c411-7b89-4a04-b2cf-3caa214405cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##run this first to install package, then delete\n",
    "pip install webdriver-manager selenium pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9796949-49e1-47a6-8803-b271ee4efc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import time \n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "from selenium.webdriver import Chrome \n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.common.by import By \n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a817af-dc9d-428f-91a4-5daf971c6928",
   "metadata": {},
   "source": [
    "Run this block below as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c58244-796c-4663-b692-e17515692114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/k5ncd_gj29q_qdsk52wqdd500000gn/T/ipykernel_4887/210964506.py:3: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True # it's more scalable to work in headless mode\n"
     ]
    }
   ],
   "source": [
    "# start by defining the options \n",
    "options = webdriver.ChromeOptions() \n",
    "options.headless = True # it's more scalable to work in headless mode \n",
    "# normally, selenium waits for all resources to download \n",
    "# we don't need it as the page also populated with the running javascript code. \n",
    "options.page_load_strategy = 'none' \n",
    "# this returns the path web driver downloaded \n",
    "chrome_path = ChromeDriverManager().install() \n",
    "chrome_service = Service(chrome_path) \n",
    "# pass the defined options and service objects to initialize the web driver \n",
    "driver = Chrome(options=options, service=chrome_service) \n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0be8e-b24d-4b77-81fc-8c2e3912ae0b",
   "metadata": {},
   "source": [
    "This stores a list of listing urls based on a desired quantity (each listing page contains 120 listings). I'm keeping the number low for now, just for efficiency but we'll have to discuss how many individual listings we want to try and scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9f1ff4-3044-4aba-897a-0fb746f2f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "page = 0\n",
    "num_pages = 3\n",
    "\n",
    "# get urls\n",
    "for x in range(num_pages):\n",
    "    page += 1 \n",
    "    url_list.append(\"https://losangeles.craigslist.org/search/apa?query=los%20angeles#search=1~list~{}~0\".format(page))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc275619-c081-4895-900e-0011d25c41ab",
   "metadata": {},
   "source": [
    "For each page of listings, we need to grab the urls for each of the 120 individual listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6947e64a-8455-4c27-a670-afa4a8232c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://losangeles.craigslist.org/lac/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://losangeles.craigslist.org/sfv/apa/d/ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://losangeles.craigslist.org/wst/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://losangeles.craigslist.org/wst/apa/d/lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://losangeles.craigslist.org/lac/apa/d/lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                urls\n",
       "0  https://losangeles.craigslist.org/lac/apa/d/lo...\n",
       "1  https://losangeles.craigslist.org/sfv/apa/d/ch...\n",
       "2  https://losangeles.craigslist.org/wst/apa/d/lo...\n",
       "3  https://losangeles.craigslist.org/wst/apa/d/lo...\n",
       "4  https://losangeles.craigslist.org/lac/apa/d/lo..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings = []\n",
    "\n",
    "for url in url_list:\n",
    "    # create WebElement of Listings Page\n",
    "    driver.get(url)\n",
    "    # find the section the listings are located in\n",
    "    content = driver.find_element(By.CSS_SELECTOR, \"div[class*='cl-results-page'\")\n",
    "    # find the section where the link to the property page is located for each 120 listings\n",
    "    for element in content.find_elements(By.TAG_NAME, \"li\")[1:]:\n",
    "        listings.append(element.find_elements(By.CSS_SELECTOR, \"div[class*='result-node-wide']>a\")[0].get_attribute(\"href\"))\n",
    "    # add delay (not sure about actually length of time delays necessary)\n",
    "    time.sleep(random.randint(1, 3))\n",
    "    \n",
    "listingsDf = pd.DataFrame(listings)\n",
    "listingsDf.rename(columns = {0:\"urls\"}, inplace = True)\n",
    "# limiting size for testing\n",
    "listingsDf = listingsDf[:20]\n",
    "# check DF\n",
    "listingsDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f36bb-26c9-4930-988e-95251310fdc1",
   "metadata": {},
   "source": [
    "Now we will scrape each webpage from the list of urls. This is where most of our development and discussion needs to occur. I've placed a temporary simple test in there for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "971acbc8-2446-4769-aba4-484e2684151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_TF = []\n",
    "for url in listingsDf['urls']:\n",
    "    r = requests.get(url)      \n",
    "    # words or phrases to \n",
    "    park_TF.append('park' in r.text.lower())\n",
    "    time.sleep(random.randint(1, 3))\n",
    "    \n",
    "listingsDf['park_TF'] = park_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80be909a-81ce-42b8-975c-68c683c8bd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "park_TF\n",
       "True     19\n",
       "False     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listingsDf.park_TF.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
